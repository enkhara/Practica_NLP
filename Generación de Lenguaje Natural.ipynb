{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementación de un modelo de generacion de lenguaje utilizando el dataset propuesto de Twitter\n",
    "\n",
    "El objetivo es simular la creación de un bot que escriba tweets de manera similar al del autor, utilizado para el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Cargamos las librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Cargamos los tweets.\n",
    "\n",
    "Para esta parte de la práctica, he utilizado los [tweets de Adam Savage](https://www.kaggle.com/speckledpingu/RawTwitterFeeds?select=AdamSavageTweets.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/AdamSavage.csv\", sep=',', decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>retweet</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1h1 hour ago</td>\n",
       "      <td>787026890305314816</td>\n",
       "      <td>/donttrythis/status/787026890305314816</td>\n",
       "      <td>False</td>\n",
       "      <td>My #Totoro cosplay at #NYCC. Photo by @nchan.p...</td>\n",
       "      <td>AdamSavage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5h5 hours ago</td>\n",
       "      <td>786968323296595968</td>\n",
       "      <td>/donttrythis/status/786968323296595968</td>\n",
       "      <td>False</td>\n",
       "      <td>The original pic @RobtheBarbarian used to crea...</td>\n",
       "      <td>AdamSavage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5h5 hours ago</td>\n",
       "      <td>786966556785782784</td>\n",
       "      <td>/donttrythis/status/786966556785782784</td>\n",
       "      <td>False</td>\n",
       "      <td>This Sad Keanu photo made by @RobtheBarbarian ...</td>\n",
       "      <td>AdamSavage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1d1 day ago</td>\n",
       "      <td>786679762525847552</td>\n",
       "      <td>/donttrythis/status/786679762525847552</td>\n",
       "      <td>False</td>\n",
       "      <td>.@tom_sachs' shop cat sits on Totoro's leaf-ha...</td>\n",
       "      <td>AdamSavage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Oct 13</td>\n",
       "      <td>786605330851467264</td>\n",
       "      <td>/donttrythis/status/786605330851467264</td>\n",
       "      <td>False</td>\n",
       "      <td>Isn't the POV video awesome!? That's what it l...</td>\n",
       "      <td>AdamSavage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           date                  id  \\\n",
       "0           0   1h1 hour ago  787026890305314816   \n",
       "1           1  5h5 hours ago  786968323296595968   \n",
       "2           2  5h5 hours ago  786966556785782784   \n",
       "3           3    1d1 day ago  786679762525847552   \n",
       "4           4         Oct 13  786605330851467264   \n",
       "\n",
       "                                     link  retweet  \\\n",
       "0  /donttrythis/status/787026890305314816    False   \n",
       "1  /donttrythis/status/786968323296595968    False   \n",
       "2  /donttrythis/status/786966556785782784    False   \n",
       "3  /donttrythis/status/786679762525847552    False   \n",
       "4  /donttrythis/status/786605330851467264    False   \n",
       "\n",
       "                                                text      author  \n",
       "0  My #Totoro cosplay at #NYCC. Photo by @nchan.p...  AdamSavage  \n",
       "1  The original pic @RobtheBarbarian used to crea...  AdamSavage  \n",
       "2  This Sad Keanu photo made by @RobtheBarbarian ...  AdamSavage  \n",
       "3  .@tom_sachs' shop cat sits on Totoro's leaf-ha...  AdamSavage  \n",
       "4  Isn't the POV video awesome!? That's what it l...  AdamSavage  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4872, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4872, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Procesamos el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "for t in df['text']:\n",
    "    text += ' ' + t\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Mapeo de los caracteres\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = sorted(list(set(text)))\n",
    "n_to_char = {n:char for n, char in enumerate(characters)}\n",
    "char_to_n = {char:n for n, char in enumerate(characters)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Procesamiento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "length = len(text)\n",
    "seq_length = 100\n",
    "\n",
    "for i in range(0, length-seq_length, 1):\n",
    "    sequence = text[i:i + seq_length]\n",
    "    label =text[i + seq_length]\n",
    "    X.append([char_to_n[char] for char in sequence])\n",
    "    Y.append(char_to_n[label])\n",
    "X_modified = np.reshape(X, (len(X), seq_length, 1))\n",
    "X_modified = X_modified / float(len(characters))\n",
    "Y_modified = np_utils.to_categorical(Y)\n",
    "vocab_size = len(characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Creamos nuestro modelo secuencial y lo entrenamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 102)               10302     \n",
      "=================================================================\n",
      "Total params: 131,502\n",
      "Trainable params: 131,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 534197 samples, validate on 28116 samples\n",
      "Epoch 1/10\n",
      "534197/534197 [==============================] - 877s 2ms/step - loss: 3.2291 - accuracy: 0.1697 - val_loss: 2.8911 - val_accuracy: 0.2298\n",
      "Epoch 2/10\n",
      "534197/534197 [==============================] - 883s 2ms/step - loss: 2.9040 - accuracy: 0.2359 - val_loss: 2.7837 - val_accuracy: 0.2571\n",
      "Epoch 3/10\n",
      "534197/534197 [==============================] - 898s 2ms/step - loss: 2.7961 - accuracy: 0.2596 - val_loss: 2.7096 - val_accuracy: 0.2717\n",
      "Epoch 4/10\n",
      "534197/534197 [==============================] - 902s 2ms/step - loss: 2.7261 - accuracy: 0.2742 - val_loss: 2.6622 - val_accuracy: 0.2797\n",
      "Epoch 5/10\n",
      "534197/534197 [==============================] - 909s 2ms/step - loss: 2.6784 - accuracy: 0.2841 - val_loss: 2.6139 - val_accuracy: 0.2880\n",
      "Epoch 6/10\n",
      "534197/534197 [==============================] - 918s 2ms/step - loss: 2.6494 - accuracy: 0.2904 - val_loss: 2.5872 - val_accuracy: 0.2987\n",
      "Epoch 7/10\n",
      "534197/534197 [==============================] - 916s 2ms/step - loss: 2.6142 - accuracy: 0.2986 - val_loss: 2.5671 - val_accuracy: 0.3022\n",
      "Epoch 8/10\n",
      "534197/534197 [==============================] - 916s 2ms/step - loss: 2.5900 - accuracy: 0.3049 - val_loss: 2.5574 - val_accuracy: 0.2999\n",
      "Epoch 9/10\n",
      "534197/534197 [==============================] - 906s 2ms/step - loss: 2.5669 - accuracy: 0.3102 - val_loss: 2.5262 - val_accuracy: 0.3133\n",
      "Epoch 10/10\n",
      "534197/534197 [==============================] - 905s 2ms/step - loss: 2.5491 - accuracy: 0.3155 - val_loss: 2.5160 - val_accuracy: 0.3132\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(X_modified.shape[1], X_modified.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(Y_modified.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "history = model.fit(X_modified, Y_modified, validation_split=0.05, batch_size=128, epochs=10, shuffle=True).history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Generación del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, string_id):\n",
    "    string_mapped = deepcopy(string_id)\n",
    "    full_string = [n_to_char[value] for value in string_mapped]\n",
    "    # Generating characters\n",
    "    for i in range(400):\n",
    "        x = np.reshape(string_mapped,(1,len(string_mapped), 1))\n",
    "        x = x / float(len(characters))\n",
    "        pred_index = np.argmax(model.predict(x, verbose=0))\n",
    "        seq = [n_to_char[value] for value in string_mapped]\n",
    "        full_string.append(n_to_char[pred_index])\n",
    "        string_mapped.append(pred_index)\n",
    "        string_mapped = string_mapped[1:len(string_mapped)]\n",
    "    text = \"\"\n",
    "    for char in full_string:\n",
    "        text = text + char\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Resultado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = generate_text(model, X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " My #Totoro cosplay at #NYCC. Photo by @nchan.pic.twitter.com/YR4oRe1zyQ The original pic @RobtheBar and the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee the seee\n"
     ]
    }
   ],
   "source": [
    "print(model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar, el resultado deja bastante que desear.\n",
    "Algunas de las cosas que podríamos modificar para que nuestro modelo generase mejores 'twitts' son:\n",
    "- Aumentar el número de epocas para que estubiera más tiempo entrenando, pero vigilando el overfitting\n",
    "- Aumentar el número de neuronas\n",
    "- Modificar el batch_size\n",
    "- El porcentaje de dropout\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La generación de lenguaje natural, a parte de ser muy costosos los entrenamientos, en mi caso cada época a tardado unos 35 min y los resultados no han sido para nada utilizables.\n",
    "\n",
    "Esta claro, que para poder tener un buen generado de textos, a parte del software, habría que entrenarlo por muchas más epocoas, intentando conseguir un accuracy del 96% para test, para poder tener un bueno generador de textos, ya que la idea es conseguir una imitación, no sólo del lenguaje natural, lo cual es fáscinante, sino que además, siga los patrones o estilo de escritura de una persona, que, almenos en mi caso, depende de si se comunica con familiares, amigos, compañeros de trabajo, adultos, niños, cambiará su registro, con lo que resulta muy complicado conseguir el objetivo planteado en este ejercicio\n",
    "\n",
    "La verdad, todo sea dicho, es que me ha faltado tiempo para entrenar y optimizar los parametros, entiendo que si hubiera conseguido, aunque sólo hubiese sido un 50% de acuracy o 60% en test, hubiera alucinado con el resultado.\n",
    "\n",
    "Aunque es el primer contacto que tengo en este campo, considero que, está muy presente en nuestro día a día,  y cada vez más.\n",
    "\n",
    "Aunque sigo prefiriendo hablar con personas :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
